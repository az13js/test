# 大话人工智能

## 人工智能的样貌

把机器学习的模型看成一个黑盒，比如这里用字母 f 来表示这个黑盒。我们把训练用的输入数据和输出数据，额，专业的说法把这些数据称作“训练集”，扔给这个黑盒 f 。尽管不同的模型不同的训练方法算法是不同的，但是综合地看，黑盒根据训练集进行一个叫做“训练”的过程，在这个过程里黑盒会调整自己以适应这些训练集。最后机器学习的模型 f 就制作好了。在利用这个黑盒 f 的时候，把跟训练集的输入数据有点像的输入数据输入给 f ，f 就能给出一个差不多的输出数据。

现在训练集总是使用爬虫等人工的手段采集到的，并且黑盒里面具体结构、训练的算法、控制训练过程的参数也需要人工设置。因此目前的所谓“人工智能”，本质上还是不能脱离“有多少人工就有多少智能”的状况。

但是这不能说明现有的模型和理论是错的。人工神经网络是对生物神经网络的仿生设计，它的结构是模仿大量生物神经彼此相互连接的特点来实现的，换句话来说它模拟了人脑神经系统运作的一些特点。所以它可以实现图像和语音的识别、风格迁移、甚至围棋竞技这些需要人类感性思维参与的、靠传统编程手段基本无法实现的东西，并且效果还很好。

但是从根本上，人类智能的机制目前还不清楚。人工神经网络只是简略地模拟了神经网络的结构，这些细胞如何生长成这样的、为什么需要这样生长，还有背后的其他一些机制都不知道。同时智能是否必须依赖这样的互联结构来实现也不确定。这就是目前的人工智能距离真正的智能之间的距离。

继续来看看黑盒 f 。假如训练集是`{x_train,y_train}`，其中的`x_train`是输入，`y_train`是输出。显然 f 在拿来用之前是需要接受`{x_train,y_train}`的洗礼的，那么`{x_train,y_train}`相当于已知量。最终，给定一个不在训练集里面的输入值 x ， f 经过计算返回 y，这个过程就相当于下面这个公式：

    y = f {x_train,y_train} (x)

也就是说这时候 f 就是一个含有相关参数`{x_train,y_train}`的数学函数。它对输入 `x` 进行了运算，输出的是 `y`。
